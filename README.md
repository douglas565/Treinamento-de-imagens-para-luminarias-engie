# ğŸ”¦ Sistema de DetecÃ§Ã£o de LuminÃ¡rias

Sistema de visÃ£o computacional para identificaÃ§Ã£o automÃ¡tica de modelo e potÃªncia (Watts) de luminÃ¡rias a partir de imagens.

## ğŸ“‹ CaracterÃ­sticas

- **OCR AvanÃ§ado**: ExtraÃ§Ã£o de texto de etiquetas e rÃ³tulos
- **ClassificaÃ§Ã£o Visual**: IdentificaÃ§Ã£o por comparaÃ§Ã£o visual quando OCR falha
- **DetecÃ§Ã£o de PotÃªncia**: Extrai valores em W, kW automaticamente
- **Bounding Boxes**: LocalizaÃ§Ã£o precisa das luminÃ¡rias na imagem
- **API REST**: Endpoint para integraÃ§Ã£o com outros sistemas
- **Processamento em Lote**: MÃºltiplas imagens simultaneamente
- **VisualizaÃ§Ã£o**: Imagens anotadas com detecÃ§Ãµes

## ğŸš€ InstalaÃ§Ã£o

### 1. Requisitos do Sistema

- Python 3.8+
- Tesseract OCR
- CUDA (opcional, para GPU)

### 2. Instalar Tesseract

**Ubuntu/Debian:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-por
```

**macOS:**
```bash
brew install tesseract tesseract-lang
```

**Windows:**
Baixe o instalador em: https://github.com/UB-Mannheim/tesseract/wiki

### 3. Instalar DependÃªncias Python

```bash
pip install -r requirements.txt
```

## ğŸ“¦ Estrutura do Projeto

```
luminaire-detector/
â”œâ”€â”€ luminaire_detector.py    # Classe principal do detector
â”œâ”€â”€ api.py                    # API REST com FastAPI
â”œâ”€â”€ train_model.py            # Script de treinamento
â”œâ”€â”€ config.json               # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt          # DependÃªncias
â”œâ”€â”€ README.md                 # Esta documentaÃ§Ã£o
â”œâ”€â”€ dataset/                  # Dataset para treinamento
â”‚   â””â”€â”€ luminaires/
â”‚       â”œâ”€â”€ LUXA200/
â”‚       â”œâ”€â”€ LUXA150/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ uploads/                  # Imagens temporÃ¡rias
â””â”€â”€ results/                  # Resultados (JSON + visualizaÃ§Ãµes)
```

## ğŸ¯ Uso BÃ¡sico

### Exemplo Simples

```python
from luminaire_detector import LuminaireDetector

# Inicializar detector
detector = LuminaireDetector(config_path="config.json")

# Processar imagem
result = detector.process_image("luminaria.jpg")

# Exibir resultados
for det in result.detections:
    print(f"Modelo: {det.model}")
    print(f"PotÃªncia: {det.power_watts}W")
    print(f"ConfianÃ§a: {det.confidence*100:.1f}%")

# Salvar visualizaÃ§Ã£o
detector.visualize_results("luminaria.jpg", result, "resultado.jpg")

# Salvar JSON
detector.save_json(result, "resultado.json")
```

### Executar Detector via CLI

```bash
python luminaire_detector.py
```

## ğŸŒ API REST

### Iniciar Servidor

```bash
python api.py
```

Servidor estarÃ¡ disponÃ­vel em: `http://localhost:8000`

### Endpoints

#### 1. Detectar LuminÃ¡ria (Upload de Imagem)

```bash
curl -X POST "http://localhost:8000/detect" \
  -F "file=@luminaria.jpg" \
  -F "save_visualization=true"
```

**Resposta:**
```json
{
  "image_id": "luminaria.jpg",
  "detections": [
    {
      "detection_id": 1,
      "bbox": [120, 80, 480, 360],
      "model": "LUXA200",
      "power_watts": 24,
      "confidence": 0.98,
      "ocr_text": "MODEL: LUXA200 24W",
      "explain": "OCR detectou informaÃ§Ãµes na etiqueta"
    }
  ],
  "processing_time_ms": 312,
  "visualization_url": "/results/result_luminaria.jpg",
  "json_url": "/results/result_luminaria.json"
}
```

#### 2. Processamento em Lote

```bash
curl -X POST "http://localhost:8000/detect/batch" \
  -F "files=@img1.jpg" \
  -F "files=@img2.jpg" \
  -F "files=@img3.jpg"
```

#### 3. Listar Modelos Conhecidos

```bash
curl http://localhost:8000/models
```

#### 4. Health Check

```bash
curl http://localhost:8000/health
```

### Swagger UI

Acesse a documentaÃ§Ã£o interativa em: `http://localhost:8000/docs`

## ğŸ§  Treinamento do Modelo

### 1. Preparar Dataset

Organize imagens na seguinte estrutura:

```
dataset/luminaires/
â”œâ”€â”€ LUXA200/
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”œâ”€â”€ img002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ LUXA150/
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ LUXB300/
    â””â”€â”€ ...
```

**RecomendaÃ§Ãµes:**
- MÃ­nimo 50-200 imagens por modelo
- Variar Ã¢ngulos, iluminaÃ§Ã£o e distÃ¢ncia
- Incluir etiquetas legÃ­veis e ilegÃ­veis
- Usar data augmentation automÃ¡tica

### 2. Treinar Classificador

```python
from train_model import LuminaireClassifier

# Criar classificador
classifier = LuminaireClassifier(num_classes=10, model_name='resnet50')

# Preparar dados
train_loader, val_loader = classifier.prepare_data(
    'dataset/luminaires', 
    batch_size=16, 
    val_split=0.2
)

# Treinar
history = classifier.train(
    train_loader, val_loader,
    epochs=50,
    lr=0.001,
    save_path='luminaire_classifier.pth'
)

# Avaliar
classifier.evaluate(val_loader)
```

Ou via CLI:
```bash
python train_model.py
```

### 3. Integrar Modelo Treinado

```python
from luminaire_detector import LuminaireDetector
import torch

detector = LuminaireDetector()

# Carregar modelo treinado
checkpoint = torch.load('luminaire_classifier.pth')
detector.model.load_state_dict(checkpoint['model_state_dict'])
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite `config.json` para customizar:

### Tabela de ReferÃªncia Modelo â†’ PotÃªncia

```json
{
  "model_power_reference": {
    "LUXA200": 24,
    "LUXA150": 18,
    "PHILIPS-LED-24W": 24
  }
}
```

### ParÃ¢metros de OCR

```json
{
  "ocr_config": {
    "tesseract_mode": 3,
    "page_segmentation_mode": 6,
    "language": "por+eng"
  }
}
```

### Threshold de ConfianÃ§a

```json
{
  "min_confidence": 0.4
}
```

## ğŸ“Š Formato de SaÃ­da JSON

```json
{
  "image_id": "luminaria.jpg",
  "detections": [
    {
      "detection_id": 1,
      "bbox": [x_min, y_min, x_max, y_max],
      "model": "LUXA200",
      "power_watts": 24,
      "confidence": 0.98,
      "ocr_text": "MODEL: LUXA200 24W",
      "explain": "OCR detectou informaÃ§Ãµes na etiqueta"
    }
  ],
  "processing_time_ms": 312
}
```

## ğŸ”§ Melhorias AvanÃ§adas

### 1. Usar YOLO para DetecÃ§Ã£o

```python
from ultralytics import YOLO

# Treinar YOLO custom
model = YOLO('yolov8n.pt')
model.train(data='luminaires.yaml', epochs=100)

# Integrar no detector
detector.yolo_model = YOLO('best.pt')
```

### 2. Usar CLIP para Zero-Shot Classification

```python
import clip
import torch

model, preprocess = clip.load("ViT-B/32")

# Classificar sem treinamento
text_inputs = torch.cat([clip.tokenize(f"a photo of a {c}") 
                         for c in class_names])
```

### 3. Melhorar OCR com EasyOCR

```python
import easyocr

reader = easyocr.Reader(['pt', 'en'])
result = reader.readtext(image)
```

## ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

- **AcurÃ¡cia do Modelo**: % de modelos corretamente identificados
- **MAE de PotÃªncia**: Erro absoluto mÃ©dio na estimativa de potÃªncia
- **Taxa de OCR**: Precision/Recall do OCR
- **ConfianÃ§a MÃ©dia**: % de detecÃ§Ãµes com confidence â‰¥ 0.8

## ğŸ› Troubleshooting

### Tesseract nÃ£o encontrado

```python
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
```

### CUDA Out of Memory

Reduza batch_size ou use CPU:
```python
detector.device = torch.device('cpu')
```

### OCR com baixa precisÃ£o

- Aumente contraste da imagem
- Use prÃ©-processamento mais agressivo
- Ajuste parÃ¢metros do Tesseract

## ğŸ“ LicenÃ§a

MIT License - Livre para uso comercial e pessoal

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie sua feature branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para o branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

## ğŸ“§ Contato

Para dÃºvidas ou suporte, abra uma issue no GitHub.

---

**Desenvolvido com â¤ï¸ usando Python, OpenCV, PyTorch e Tesseract**